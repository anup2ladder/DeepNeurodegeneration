{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate progressive neurodegeneration in trained VGG19 CNN and evaluate accuracy on CIFAR100\n",
    "\n",
    "Use the trained \"healthy\" model and defined injury map to simulate progressive neurodegeneration by synaptic ablation on a CNN. Evaluate performance at the class and superclass level on CIFAR100 over the course of neurodegeneration by calculating:\n",
    "- Class-wise classification accuracy\n",
    "- Superclass-wise classification accuracy\n",
    "- \"Errors within the correct superclass\": What percentage of misclassifications at the class level were still correct at the superclass level (e.g. a rose misclassified as a tulip, another member of the superclass flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injury Levels\n",
    "How much the network will be injured at each step in the simulation. \n",
    "\n",
    "The length of the list *injury_levels* indicates how many injury steps will be performed, and the corresponding value at that list location is the percentage of weights to be injured in each layer (expressed as a fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to 50% injury with 0.1% increments in number of weights injured\n",
    "injury_levels = [x/1000 for x in range(0,501,1)]  # start, end, step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifiable value of the run ID\n",
    "run = '0001'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_dir = '../Trained_Models'\n",
    "trained_prefix = '/VGG19-Exp01-TrainedModel-run'\n",
    "trained_suffix = '.h5'\n",
    "\n",
    "# Filename\n",
    "model_filename = trained_dir + trained_prefix + str(run) + trained_suffix\n",
    "print(\"Model:\\n\\t\",model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injury map filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = '../Injury_Maps'\n",
    "map_prefix = '/VGG19-Exp02-InjuryMap-run'\n",
    "map_suffix = '.pickle'\n",
    "\n",
    "# Filename\n",
    "map_filename = map_dir + map_prefix + str(run) + map_suffix\n",
    "print(\"Injury map:\\n\\t\",map_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Output filename and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './RESULTS'\n",
    "save_prefix = '/VGG19-Exp03-InjuredCNN-Accuracy-run'\n",
    "save_suffix = '.csv'\n",
    "\n",
    "save_filename = save_dir + save_prefix + str(run) + save_suffix\n",
    "\n",
    "print(\"Save to:\\n\\t\", save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to class to superclass conversion\n",
    "A pickled list that maps the class label of CIFAR100 to its corresponding superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_class_superclass_conversion = \"../Data/finelabel_to_coarselabel_conversionlist.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to pre-process data for VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"Pre-processes the data for the trained model\"\"\"\n",
    "    X_p = K.applications.vgg19.preprocess_input(X.astype('float32')) # pre-processed input\n",
    "    Y_p = K.utils.to_categorical(Y, classes) # one-hot matrix\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Read variables in and out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_out_variable(variable, filename, folder_path='.'):\n",
    "    \"\"\"\n",
    "    Simple function to pickle out a single python variable\n",
    "    given the filename (filename.pickle), as a string\n",
    "    and a foldername ('.' for current directory) as a string\n",
    "    \"\"\"\n",
    "    # Open the file, call it \"results.pickle\"\n",
    "    pickle_out = open(os.path.join(folder_path, filename), 'wb')\n",
    "    # Write out the results to defined file\n",
    "    pickle.dump(variable, pickle_out)\n",
    "    # Close the file\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_in_variable(filename, folder_path='.'):\n",
    "    \"\"\"\n",
    "    Simple function to pickle in a single python variable\n",
    "    given the filename (filename.pickle), as a string\n",
    "    and a foldername ('.' for current directory) as a string\n",
    "    \"\"\"\n",
    "    # Open the file\n",
    "    pickle_in = open(os.path.join(folder_path, filename), 'rb')\n",
    "    # Read in the variable\n",
    "    variable = pickle.load(pickle_in)\n",
    "    # Close the file\n",
    "    pickle_in.close()\n",
    "\n",
    "    # Return the variable\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to injure weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_progressive_injury(initial_weights, injury_order, injury_amount):\n",
    "    \"\"\"\n",
    "    Given (3):\n",
    "        initial weights: A set of (healthy) weights\n",
    "        injury_order: Order of weights to injure for each layer.\n",
    "        injury_amount: Proportion of weights (0 to 1) to injure in each layer\n",
    "    \n",
    "    Apply an injury (setting weights to 0) to injury_amount*100 % of WEIGHTS\n",
    "    in a given layer in a fixed-random fashion.\n",
    "    \n",
    "    Fixed because the order in which the weights are injured is defined\n",
    "    elsewhere and passed in.\n",
    "    \n",
    "    The biases are not modified\n",
    "    \n",
    "    Returns (2):\n",
    "        final_weights: updated value of weights with a given injury applied\n",
    "            to be loaded back into the model\n",
    "        injury_mask: information on whether a given weight is injured [0] or \n",
    "            unmodified [1]. Same structure as the initial_weights and \n",
    "            final_weights (lists with numpy arrays)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialize the injury mask to multiply the initial weights with\n",
    "    ##. A list of the same size as the weights, containing 0's and 1's\n",
    "    injure_mask = [None]*len(initial_weights)\n",
    "    \n",
    "    for i in range(len(injure_mask)):\n",
    "        if initial_weights[i].ndim == 1:  # Non-weight indices\n",
    "            # If this is a bias layer or batch norm layer\n",
    "            # Just make a list of 1's of the given size\n",
    "            x = [1]*initial_weights[i].size\n",
    "            \n",
    "            # NOTE:\n",
    "            ## If you want to injure biases, then modify the script here\n",
    "            ## You will also need to modify the injury_order defined\n",
    "            ## in \"2. CreateInjuryMap\"\n",
    "        \n",
    "        else:  # For weights\n",
    "            # If not a bias layer, then assume weight layer\n",
    "            # which is true for VGG19.\n",
    "            # NOTE: This would need to be modified for other networks\n",
    "\n",
    "            # Injure x% of weights in this layer\n",
    "\n",
    "            # Total number of weights in the layer\n",
    "            num_weights = initial_weights[i].size\n",
    "            \n",
    "            # Number of weights to spare\n",
    "            num_to_spare = round(num_weights*(1-injury_amount))\n",
    "            # If rounding results in no weights spared, set to minimum 1\n",
    "            if num_to_spare < 1:\n",
    "                num_to_spare = 1\n",
    "                \n",
    "            # Number of weights to injure\n",
    "            num_to_injure = num_weights - num_to_spare\n",
    "            \n",
    "            # Create numpy array with the correct number of injured\n",
    "            # and spared weights (in that order)\n",
    "            ## The order of this 1-d array will need to be modified\n",
    "            x = np.array([0]*num_to_injure + [1]*num_to_spare)  # np array\n",
    "            \n",
    "            # Then, re-order/shuffle this list (stored as np array)\n",
    "            # according to a previously-defined randomized order\n",
    "            # defined in injury_order[i]\n",
    "            x = x[injury_order[i]]\n",
    "        \n",
    "        # Reshape x to match this given list element (either weight or bias)\n",
    "        x = np.reshape(x, initial_weights[i].shape)  # np array\n",
    "        # Assign to the injure_list mask element\n",
    "        injure_mask[i] = x  # list, with element as np array\n",
    "    \n",
    "    # Create the list of injured weights\n",
    "    # by multiplying the initial weights with the mask\n",
    "    # As the bias elements of the mask are 1, biases are not modified\n",
    "    final_weights = [None]*len(initial_weights)\n",
    "    for w in range(0, len(initial_weights)):\n",
    "        final_weights[w] = initial_weights[w]*injure_mask[w]\n",
    "\n",
    "        \n",
    "    return final_weights, injure_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "- Previously trained model\n",
    "- Previously created injury map\n",
    "- CIFAR100 images and label information (class and superclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.models.load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Healthy Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_healthy = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Injury Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_map = pickle_in_variable(map_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load CIFAR100 information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw cifar100 dataset\n",
    "(raw_X_train, raw_Y_train), (raw_X_test, raw_Y_test) = K.datasets.cifar100.load_data()\n",
    "classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training and validation data\n",
    "X_test, Y_test = preprocess_data(raw_X_test, raw_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list that maps each class label to its corresponding superclass label\n",
    "convert_class_to_super = pickle_in_variable(path_to_class_superclass_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truths as list\n",
    "gt_class = [raw_Y_test[i][0] for i in range(len(raw_Y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superclass ground truths as list\n",
    "gt_super = [convert_class_to_super[i] for i in gt_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the experiment\n",
    "Loop through the injury levels. At each injury level:\n",
    "- Injure the model by ablating the given % of model weights\n",
    "    - Create a set of injured weights\n",
    "    - Load into the model\n",
    "- Evaluate the model on the test set, return:\n",
    "    - Class accuracy\n",
    "    - Superclass accuracy\n",
    "    - Class errors within the correct superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of injury steps\n",
    "num_inj = len(injury_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "acc_overall = [-1.]*num_inj  # Class accuracy\n",
    "acc_super = [-1.]*num_inj  # Superclass accuracy\n",
    "err_correct_super = [-1.]*num_inj  # Errors within the correct superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop Through injury levels\n",
    "for i in range(num_inj):\n",
    "    # Set injury level for this loop\n",
    "    inj = injury_levels[i]\n",
    "    \n",
    "    print(\"Inj:\", inj)\n",
    "    \n",
    "    # Get injured weights\n",
    "    weights_injured, mask_injured = apply_progressive_injury(\n",
    "        initial_weights = weights_healthy,\n",
    "        injury_order = injury_map,\n",
    "        injury_amount = inj\n",
    "    )\n",
    "    \n",
    "    # Set model with injured weights\n",
    "    model.set_weights(weights_injured)\n",
    "    \n",
    "    # Get model class predictions\n",
    "    predicted_class = model.predict_classes(X_test, batch_size=500, verbose=1)\n",
    "    # Convert predictions to a list\n",
    "    y_class = list(predicted_class)\n",
    "    # Get corresponding superclass of predictions\n",
    "    y_super = [convert_class_to_super[k] for k in y_class]\n",
    "    \n",
    "    # Evaluate\n",
    "    \n",
    "    # Overall accuracy\n",
    "    acc_overall[i] = sklearn.metrics.accuracy_score(gt_class, y_class)\n",
    "    \n",
    "    # Superclass accuracy\n",
    "    acc_super[i] = sklearn.metrics.accuracy_score(gt_super, y_super)\n",
    "    \n",
    "    # Errors in superclass (fraction)\n",
    "    ## Get list of superclass predictions of wrong fine-class predictions\n",
    "    wrong_y_super = list()\n",
    "    wrong_gt_super = list()\n",
    "    for k in range(len(y_class)):\n",
    "        if y_class[k] != gt_class[k]:  # Not equal\n",
    "            wrong_y_super.append(y_super[k])\n",
    "            wrong_gt_super.append(gt_super[k])\n",
    "    ## Calculate superclass accuracy\n",
    "    ## Of errors, look at what fraction are in the correct superclass\n",
    "    err_correct_super[i] = sklearn.metrics.accuracy_score(wrong_gt_super, wrong_y_super)\n",
    "    \n",
    "    print(\n",
    "          \"\\tAcc:\", acc_overall[i],\n",
    "          \"\\tSuper Acc:\", acc_super[i],\n",
    "          \"\\tErr Corr Super:\", err_correct_super[i]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make directory if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If results directory doesn't exist, make it\n",
    "if not os.path.exists(save_dir):\n",
    "    print(\"RESULTS directory doesn't exist, creating one\")\n",
    "    os.makedirs(save_dir)\n",
    "else:\n",
    "    print('RESULTS directory exists, no action taken')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make a dictionary of the results\n",
    "results = dict(\n",
    "    Injury_Amount = injury_levels,\n",
    "    Overall_Accuracy = acc_overall,\n",
    "    Superclass_Accuracy = acc_super,\n",
    "    Errors_within_Correct_Superclass = err_correct_super\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a dataframe\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "results_df.to_csv(save_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
